

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>教師あり学習 &mdash; Machine Learning: Theory and Implementation 0.0.1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="参考文献" href="reference.html" />
    <link rel="prev" title="機械学習の概念" href="20190316.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> Machine Learning: Theory and Implementation
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="20190225.html">線形代数</a></li>
<li class="toctree-l1"><a class="reference internal" href="20190316.html">機械学習の概念</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">教師あり学習</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#トレーニングセット">トレーニングセット</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#[定義]-トレーニングセット">[定義] トレーニングセット</a></li>
<li class="toctree-l3"><a class="reference internal" href="#[問題]">[問題]</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#仮説関数">仮説関数</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#[定義]-仮説関数">[定義] 仮説関数</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#線形回帰">線形回帰</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#[定義]-線形回帰">[定義] 線形回帰</a></li>
<li class="toctree-l3"><a class="reference internal" href="#[問題]">[問題]</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#目的関数">目的関数</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#[定義]-学習アルゴリズム，目的関数">[定義] 学習アルゴリズム，目的関数</a></li>
<li class="toctree-l3"><a class="reference internal" href="#[定義]-平均二乗誤差関数">[定義] 平均二乗誤差関数</a></li>
<li class="toctree-l3"><a class="reference internal" href="#[問題]">[問題]</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#最急降下法">最急降下法</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#[定義]-勾配ベクトル">[定義] 勾配ベクトル</a></li>
<li class="toctree-l3"><a class="reference internal" href="#[問題]">[問題]</a></li>
<li class="toctree-l3"><a class="reference internal" href="#[定義]-最急降下法">[定義] 最急降下法</a></li>
<li class="toctree-l3"><a class="reference internal" href="#[問題]">[問題]</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#デザイン行列">デザイン行列</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#[定義]-デザイン行列">[定義] デザイン行列</a></li>
<li class="toctree-l3"><a class="reference internal" href="#[問題]">[問題]</a></li>
<li class="toctree-l3"><a class="reference internal" href="#[問題]">[問題]</a></li>
<li class="toctree-l3"><a class="reference internal" href="#[問題]">[問題]</a></li>
<li class="toctree-l3"><a class="reference internal" href="#[定理]">[定理]</a></li>
<li class="toctree-l3"><a class="reference internal" href="#[問題]">[問題]</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Pandas,-Numpy,-Matplotlibによるスクラッチ実装">Pandas, Numpy, Matplotlibによるスクラッチ実装</a></li>
<li class="toctree-l2"><a class="reference internal" href="#kaggle-APIによるデータのダウンロード">kaggle APIによるデータのダウンロード</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#[Jupyter]-エクスクラメーションによるbashコマンドの実行">[Jupyter] エクスクラメーションによるbashコマンドの実行</a></li>
<li class="toctree-l3"><a class="reference internal" href="#[bash]-フォルダの作成">[bash] フォルダの作成</a></li>
<li class="toctree-l3"><a class="reference internal" href="#[kaggle-API]-開催中のコンペティションのリストを表示">[kaggle API] 開催中のコンペティションのリストを表示</a></li>
<li class="toctree-l3"><a class="reference internal" href="#[kaggle-API]-指定したコンペのデータを任意のフォルダにダウンロード">[kaggle API] 指定したコンペのデータを任意のフォルダにダウンロード</a></li>
<li class="toctree-l3"><a class="reference internal" href="#[bash]-任意のフォルダに格納されているファイルを確認する">[bash] 任意のフォルダに格納されているファイルを確認する</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="reference.html">参考文献</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Machine Learning: Theory and Implementation</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>教師あり学習</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/20190317.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 5ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="教師あり学習">
<h1>教師あり学習<a class="headerlink" href="#教師あり学習" title="Permalink to this headline">¶</a></h1>
<div class="section" id="トレーニングセット">
<h2>トレーニングセット<a class="headerlink" href="#トレーニングセット" title="Permalink to this headline">¶</a></h2>
<p>教師あり学習は，特徴量と目的変数の組のデータを用いて学習する．学習に使用するデータをトレーニングセットという．</p>
<div class="section" id="[定義]-トレーニングセット">
<h3>[定義] トレーニングセット<a class="headerlink" href="#[定義]-トレーニングセット" title="Permalink to this headline">¶</a></h3>
<p><span class="math notranslate nohighlight">\(\{(\mathbf{x}^{(i)},y^{(i)})\}_{i=1}^m \subset (({\cal X}_1 \times {\cal X}_2\times \cdots \times{\cal X}_n) \times {\cal Y})^m\)</span>を<strong>トレーニングセット(training set)</strong>という．ここで，<span class="math notranslate nohighlight">\(m\)</span>は<strong>トレーニングサンプル数(number of training examples)</strong>，<span class="math notranslate nohighlight">\(\mathbf{x}^{(i)} \in {\cal X}_1 \times {\cal X}_2\times \cdots \times {\cal X}_n\)</span>は<span class="math notranslate nohighlight">\(i\)</span>番目の<span class="math notranslate nohighlight">\(n\)</span>個の<strong>入力変数(input
variables)</strong>または<strong>特徴量(features)</strong>で，<span class="math notranslate nohighlight">\(\mathbf{x}^{(i)}=(x_1^{(i)},x_2^{(i)},\ldots,x_n^{(i)})^T\)</span>と表す．また，<span class="math notranslate nohighlight">\(y^{(i)} \in {\cal Y}\)</span>は<span class="math notranslate nohighlight">\(i\)</span>番目の<strong>出力変数(output variable)</strong>または<strong>目的変数(target variable)</strong>である．また，トレーニングセットの<span class="math notranslate nohighlight">\(i\)</span>番目の要素<span class="math notranslate nohighlight">\((\mathbf{x}^{(i)},y^{(i)})\in ({\cal X}_1 \times {\cal X}_2\times \cdots \times{\cal X}_n) \times {\cal Y}\)</span>を<strong>トレーニングサンプル(training
example)</strong>という．また，入力変数のとる空間<span class="math notranslate nohighlight">\({\cal X}_1 \times {\cal X}_2\times \cdots \times{\cal X}_n\)</span>を<strong>入力変数空間(space of input values)</strong>，出力変数のとる空間<span class="math notranslate nohighlight">\({\cal Y}\)</span>を<strong>出力変数空間(space of output values)</strong>という．</p>
<p><strong>注意</strong></p>
<p>一般的に(特段の加工をしていない)トレーニングセットには文字列なども含まれるため，特徴量のとりうる集合として数の集合を仮定していないことを明確にするために，単なる集合<span class="math notranslate nohighlight">\({\cal X}_j\)</span>と表記している．</p>
</div>
<div class="section" id="[問題]">
<h3>[問題]<a class="headerlink" href="#[問題]" title="Permalink to this headline">¶</a></h3>
<p>次のトレーニングセットにおいて，<span class="math notranslate nohighlight">\(x_3^{(4)}, x_4^{(3)}, y^{(2)}, \mathbf{x}^{(1)}\)</span>を答えよ．</p>
<table border="1" class="docutils">
<colgroup>
<col width="11%" />
<col width="18%" />
<col width="18%" />
<col width="18%" />
<col width="18%" />
<col width="16%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><span class="math notranslate nohighlight">\(i\)</span></th>
<th class="head"><span class="math notranslate nohighlight">\(x_1^{(i)}\)</span></th>
<th class="head"><span class="math notranslate nohighlight">\(x_2^{(i)}\)</span></th>
<th class="head"><span class="math notranslate nohighlight">\(x_3^{(i)}\)</span></th>
<th class="head"><span class="math notranslate nohighlight">\(x_4^{(i)}\)</span></th>
<th class="head"><span class="math notranslate nohighlight">\(y^{(i)}\)</span></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>1</td>
<td>2104</td>
<td>5</td>
<td>1</td>
<td>apple</td>
<td>460</td>
</tr>
<tr class="row-odd"><td>2</td>
<td>1416</td>
<td>5</td>
<td>2</td>
<td>melon</td>
<td>232</td>
</tr>
<tr class="row-even"><td>3</td>
<td>1534</td>
<td>3</td>
<td>2</td>
<td>lemon</td>
<td>315</td>
</tr>
<tr class="row-odd"><td>4</td>
<td>852</td>
<td>2</td>
<td>1</td>
<td>tomato</td>
<td>178</td>
</tr>
</tbody>
</table>
<p><strong>解答)</strong></p>
<p><span class="math notranslate nohighlight">\(x_3^{(4)}=1,~x_4^{(3)}={\rm lemon},~y^{(2)}=232,~\mathbf{x}^{(1)}=(2104, 5, 1, {\rm apple})^T\)</span>．</p>
</div>
</div>
<div class="section" id="仮説関数">
<h2>仮説関数<a class="headerlink" href="#仮説関数" title="Permalink to this headline">¶</a></h2>
<p>教師あり学習を使って解きたいタスク<span class="math notranslate nohighlight">\(T\)</span>は，入力変数から出力変数を予測することであるが，それは言い換えると入力変数を引数として出力変数を出力する写像を設定することである．この写像を仮説関数という．仮説関数を以下で定義する．</p>
<div class="section" id="[定義]-仮説関数">
<h3>[定義] 仮説関数<a class="headerlink" href="#[定義]-仮説関数" title="Permalink to this headline">¶</a></h3>
<p>入力変数<span class="math notranslate nohighlight">\(\mathbf{x}\)</span>から出力変数<span class="math notranslate nohighlight">\(y\)</span>への写像<span class="math notranslate nohighlight">\(h:{\cal X}_1 \times {\cal X}_2\times \cdots \times{\cal X}_n \to {\cal Y}\)</span>，すなわち<span class="math notranslate nohighlight">\(h_{\mathbf{\theta}}(\mathbf{x})\)</span>を<strong>仮説関数(hypothesis function)</strong>という．ここで，<span class="math notranslate nohighlight">\(\mathbf{\theta}\)</span>は仮説関数の<strong>パラメータ</strong>である(パラメータは複数あることがほとんどなのでベクトルとしている)．</p>
<p>すなわち，教師あり学習とは，仮説関数を設定し，トレーニングセットを用いて仮説関数の最適なパラメータを決定することといえる．最適なパラメータを決定できれば，そのパラメータをセットした仮説関数にデータを流し込むことで，そのデータに対する予測値を計算できる．</p>
</div>
</div>
<div class="section" id="線形回帰">
<h2>線形回帰<a class="headerlink" href="#線形回帰" title="Permalink to this headline">¶</a></h2>
<p>仮説関数は自らで与える必要があるが，仮説関数の形によって，教師あり学習に特別な名前がつくものがある．例えば，仮説関数を線形関数とし，出力変数空間を<span class="math notranslate nohighlight">\({\cal Y}=\mathbb{R}\)</span>としたときは線形回帰という．</p>
<div class="section" id="[定義]-線形回帰">
<h3>[定義] 線形回帰<a class="headerlink" href="#[定義]-線形回帰" title="Permalink to this headline">¶</a></h3>
<p>トレーニングセット<span class="math notranslate nohighlight">\(\{(\mathbf{x}^{(i)},y^{(i)})\}_{i=1}^m \subset (\mathbb{R}^n \times {\cal Y})^m\)</span>について，<span class="math notranslate nohighlight">\({\cal Y}=\mathbb{R}\)</span>であり，かつ仮説関数が式(1)である教師あり学習を，特に<strong>線形回帰(linear
regression)</strong>という．ここで，特徴量<span class="math notranslate nohighlight">\(\mathbf{x}^{(i)}\)</span>は，常に1の値をとるような特徴量<span class="math notranslate nohighlight">\(x_0^{(i)}=1\)</span>を付して<span class="math notranslate nohighlight">\(\mathbf{x}^{(i)}=(x_0^{(i)},x_1^{(i)},x_2^{(i)},\ldots,x_n^{(i)})^T \in 1 \times \mathbb{R}^n \subset \mathbb{R}^{n+1}\)</span>と置き直すこととする．また，<span class="math notranslate nohighlight">\(\mathbf{\theta}=(\theta_0,\theta_1,\ldots,\theta_n)^T \in \mathbb{R}^{n+1}\)</span>とする．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
h_{\mathbf{\theta}}(\mathbf{x}^{(i)}) &amp;= \theta_0 x_0^{(i)}+\theta_1 x_1^{(i)} +\theta_2 x_2^{(i)}+\cdots + \theta_n x_n^{(i)} \nonumber \\
&amp;= \sum_{j=0}^n \theta_j x_j^{(i)}\nonumber \\
&amp;= \mathbf{\theta}^T \mathbf{x}^{(i)} \tag{1}
\end{align}\end{split}\]</div>
<p><strong>注意</strong></p>
<p>仮説関数の形より，線形回帰を用いるためには特徴量を引数にして数値計算を行う必要があるので，トレーニングセット<span class="math notranslate nohighlight">\(\{(\mathbf{x}^{(i)},y^{(i)})\}_{i=1}^m \subset (({\cal X}_1 \times {\cal X}_2\times \cdots \times{\cal X}_n) \times {\cal Y})^m\)</span>に文字列が含まれる場合はそのまま適用できず，何らかの規則で数値に変換して<span class="math notranslate nohighlight">\(\{(\mathbf{x}^{(i)},y^{(i)})\}_{i=1}^m \subset (\mathbb{R}^n \times \mathbb{R})^m\)</span>の形にしなければならない．このような変換を行う作業を<strong>特徴量エンジニアリング(feature
engineerring)</strong>という．特徴量エンジニアリングの話は後で述べる．</p>
</div>
<div class="section" id="[問題]">
<h3>[問題]<a class="headerlink" href="#[問題]" title="Permalink to this headline">¶</a></h3>
<p>ある大学生について，1年次の成績で優をとった個数から2年次にいくつ優をとるのか予測したい．そこで，何人かの大学生の1年次の成績の優の個数<span class="math notranslate nohighlight">\(x_1\)</span>と2年次の成績の優の個数<span class="math notranslate nohighlight">\(y\)</span>を集めた．その結果が次表である．このとき，次の問いに答えよ．</p>
<table border="1" class="docutils">
<colgroup>
<col width="54%" />
<col width="46%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><span class="math notranslate nohighlight">\(x_1\)</span></th>
<th class="head"><span class="math notranslate nohighlight">\(y\)</span></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>3</td>
<td>4</td>
</tr>
<tr class="row-odd"><td>2</td>
<td>1</td>
</tr>
<tr class="row-even"><td>4</td>
<td>3</td>
</tr>
<tr class="row-odd"><td>0</td>
<td>1</td>
</tr>
</tbody>
</table>
<ol class="arabic simple">
<li><span class="math notranslate nohighlight">\(m\)</span>はいくつか．</li>
<li>仮説関数として<span class="math notranslate nohighlight">\(h_{\mathbf{\theta}}(\mathbf{x})=\theta_0+\theta_1 x_1\)</span>を設定し，本トレーニングセットを用いて線形回帰を行なった結果，パラメータは<span class="math notranslate nohighlight">\(\theta_0=-1,~\theta_1=2\)</span>となった．このとき，1年次の優の個数が6だった大学生の2年次の優の個数を予測せよ．</li>
</ol>
<p><strong>解答)</strong></p>
<ol class="arabic simple">
<li><span class="math notranslate nohighlight">\(m=4\)</span>．</li>
<li><span class="math notranslate nohighlight">\(h_{\mathbf{\theta}}(\mathbf{x})=-1+2x_1\)</span>なので，<span class="math notranslate nohighlight">\(h_{\mathbf{\theta}}(6)=-1+2\cdot 6=11\)</span>．</li>
</ol>
</div>
</div>
<div class="section" id="目的関数">
<h2>目的関数<a class="headerlink" href="#目的関数" title="Permalink to this headline">¶</a></h2>
<p>さて，仮説関数のパラメータ<span class="math notranslate nohighlight">\(\mathbf{\theta}\)</span>をどう決めるかという問題がある．パラメータをでたらめに与えても良い予測値を返さないので，経験<span class="math notranslate nohighlight">\(E\)</span>のトレーニングセットを使って，性能指標<span class="math notranslate nohighlight">\(P\)</span>を高めるように仮説関数のパラメータを更新していくことが必要になる．この手順を学習アルゴリズムといい，性能指標を測る関数を目的関数という．</p>
<div class="section" id="[定義]-学習アルゴリズム，目的関数">
<h3>[定義] 学習アルゴリズム，目的関数<a class="headerlink" href="#[定義]-学習アルゴリズム，目的関数" title="Permalink to this headline">¶</a></h3>
<p>性能指標を測る関数<span class="math notranslate nohighlight">\(J(\mathbf{\theta})\)</span>を<strong>目的関数</strong>または<strong>コスト関数(cost function)</strong>といい，この目的関数で測った性能指標が良くなるように仮説関数(のパラメータ<span class="math notranslate nohighlight">\(\mathbf{\theta}\)</span>)を更新していく手順を<strong>学習アルゴリズム(learning algorithm)</strong>という．</p>
<p>回帰問題における性能指標としては，各トレーニングサンプル<span class="math notranslate nohighlight">\((\mathbf{x}^{(i)},y^{(i)})\)</span>における仮説関数<span class="math notranslate nohighlight">\(h_{\mathbf{\theta}}(\mathbf{x}^{(i)})\)</span>と<span class="math notranslate nohighlight">\(y^{(i)}\)</span>の二乗誤差平均が考えられる．この二乗誤差平均を計算する目的関数を平均二乗誤差関数という．</p>
</div>
<div class="section" id="[定義]-平均二乗誤差関数">
<h3>[定義] 平均二乗誤差関数<a class="headerlink" href="#[定義]-平均二乗誤差関数" title="Permalink to this headline">¶</a></h3>
<p>トレーニングセット<span class="math notranslate nohighlight">\(\{(\mathbf{x}^{(i)},y^{(i)})\}_{i=1}^m \subset ((1 \times \mathbb{R}^n) \times \mathbb{R})^m\)</span>について，式(2)で表される目的関数<span class="math notranslate nohighlight">\(J(\mathbf{\theta})\)</span>を<strong>平均二乗誤差関数(mean squared error function)</strong>という．</p>
<div class="math notranslate nohighlight">
\[\begin{align}
J(\mathbf{\theta}) = \frac{1}{2m}\sum_{i=1}^m (h_{\mathbf{\theta}}(\mathbf{x}^{(i)})-y^{(i)})^2 \tag{2}
\end{align}\]</div>
<p><strong>注意</strong></p>
<p><span class="math notranslate nohighlight">\(m\)</span>ではなく<span class="math notranslate nohighlight">\(2m\)</span>で割っているのは，微分したときに出てくる2が消えるようにしているからである．<span class="math notranslate nohighlight">\(m\)</span>でも特段の問題はない(同じ結果が得られる)．</p>
</div>
<div class="section" id="[問題]">
<h3>[問題]<a class="headerlink" href="#[問題]" title="Permalink to this headline">¶</a></h3>
<p>ある大学生について，1年次の成績で優をとった個数から2年次にいくつ優をとるのか予測したい．そこで，何人かの大学生の1年次の成績の優の個数<span class="math notranslate nohighlight">\(x_1\)</span>と2年次の成績の優の個数<span class="math notranslate nohighlight">\(y\)</span>を集めてトレーニングセット(下表)とし，仮説関数として<span class="math notranslate nohighlight">\(h_{\mathbf{\theta}}(\mathbf{x})=\theta_0+\theta_1 x_1\)</span>を設定して線形回帰を行なうことにした．このとき，次の問いに答えよ．</p>
<table border="1" class="docutils">
<colgroup>
<col width="54%" />
<col width="46%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><span class="math notranslate nohighlight">\(x_1\)</span></th>
<th class="head"><span class="math notranslate nohighlight">\(y\)</span></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>3</td>
<td>4</td>
</tr>
<tr class="row-odd"><td>2</td>
<td>1</td>
</tr>
<tr class="row-even"><td>4</td>
<td>3</td>
</tr>
<tr class="row-odd"><td>0</td>
<td>1</td>
</tr>
</tbody>
</table>
<ol class="arabic simple">
<li>平均二乗誤差関数<span class="math notranslate nohighlight">\(J(\mathbf{\theta})\)</span>を書き下し，<span class="math notranslate nohighlight">\(\theta_0,~\theta_1\)</span>の関数として表せ(引数がわかりやすいように<span class="math notranslate nohighlight">\(J(\theta_0, \theta_1)\)</span>と書くことにする)．</li>
<li>線形回帰の結果，パラメータは<span class="math notranslate nohighlight">\(\theta_0=-1,~\theta_1=2\)</span>となった．このときの平均二乗誤差関数<span class="math notranslate nohighlight">\(J(-1, 2)\)</span>の値を求めよ．</li>
</ol>
<p><strong>解答)</strong></p>
<ol class="arabic simple">
<li>平均二乗誤差関数の定義に，与えられた仮説関数とトレーニングセットを具体的に代入すると，</li>
</ol>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
J(\theta_0, \theta_1) &amp;=\frac{1}{2\cdot 4}\sum_{i=1}^4 (\theta_0+\theta_1 x_1^{(i)}-y^{(i)})^2 \\
&amp;=\frac{1}{8}\left((\theta_0+3\theta_1-4)^2+(\theta_0+2\theta_1-1)^2+(\theta_0+4\theta_1-3)^2+(\theta_0-1)^2\right) \\
&amp;=\frac{1}{8}(4\theta_0^2+29\theta_1^2+18\theta_0\theta_1-18\theta_0-52\theta_1+27)
\end{align}\end{split}\]</div>
<ol class="arabic simple" start="2">
<li>実際に<span class="math notranslate nohighlight">\(\theta_0=-1, \theta_1=2\)</span>を代入して計算すると，<span class="math notranslate nohighlight">\(J(-1, 2)=\frac{25}{8}\)</span>となる．</li>
</ol>
<p><strong>注意</strong></p>
<p>学習アルゴリズムにおいては，動かす文字はパラメータ<span class="math notranslate nohighlight">\(\theta\)</span>であり，トレーニングセット<span class="math notranslate nohighlight">\(\mathbf{x}^{(i)},y^{(i)}\)</span>ではない．トレーニングセットを所与のものとして，目的関数<span class="math notranslate nohighlight">\(J(\theta)\)</span>についてパラメータ<span class="math notranslate nohighlight">\(\theta\)</span>を色々動かして良くなるような<span class="math notranslate nohighlight">\(\theta\)</span>を見つけることが学習アルゴリズムの目的である．</p>
</div>
</div>
<div class="section" id="最急降下法">
<h2>最急降下法<a class="headerlink" href="#最急降下法" title="Permalink to this headline">¶</a></h2>
<p>「性能指標が良くなるように仮説関数のパラメータ<span class="math notranslate nohighlight">\(\mathbf{\theta}\)</span>をアップデートしていく」とはどういうことか．目的関数が平均二乗誤差関数の場合，その平均二乗誤差がどんどん小さくなっていくことが，性能指標が良くなっていくといえる．すなわち，目的関数を最小にするパラメータ<span class="math notranslate nohighlight">\(\mathbf{\theta}\)</span>を見つければよい．それを見つけるための手法が学習アルゴリズムである．</p>
<p>学習アルゴリズムの中で一般的なものとして最急降下法がある．最急降下法とは，目的関数<span class="math notranslate nohighlight">\(J(\mathbf{\theta})\)</span>のグラフ上に初期値として適当に点を打ち(すなわちパラメータ<span class="math notranslate nohighlight">\(\mathbf{\theta}\)</span>として具体的に何か適当な初期値を決め），その点から周辺を見渡してもっとも勾配が急な方向に一定程度進み，進んだ後の点からまた周辺を見渡してもっとも勾配が急な方向に一定程度進み，，，を繰り返して，どこを見渡しても勾配がないような点を探す方法である．</p>
<p>最急降下法を行うためには，関数上のある点について勾配が急な方向はどの方向であるかを計算しなければならない．勾配が最も急な方向を向くベクトルを勾配ベクトルといい，以下で定義される．</p>
<div class="section" id="[定義]-勾配ベクトル">
<h3>[定義] 勾配ベクトル<a class="headerlink" href="#[定義]-勾配ベクトル" title="Permalink to this headline">¶</a></h3>
<p><span class="math notranslate nohighlight">\(k\)</span>次元ベクトル<span class="math notranslate nohighlight">\(\mathbf{\theta}=(\theta_1,\theta_2,\ldots,\theta_k)^T\)</span>からスカラー値に写る関数<span class="math notranslate nohighlight">\(f(\mathbf{\theta})\)</span>，すなわち<span class="math notranslate nohighlight">\(f:\mathbf{\theta} \in \mathbb{R}^k \to \mathbb{R}\)</span>である関数<span class="math notranslate nohighlight">\(f(\mathbf{\theta})\)</span>において，<strong>勾配ベクトル</strong><span class="math notranslate nohighlight">\(\nabla_{\mathbf{\theta}}f=\frac{\partial f}{\partial \mathbf{\theta}}\in \mathbb{R}^k\)</span>は次式で定義される．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
\nabla_{\mathbf{\theta}}f = \frac{\partial f}{\partial \mathbf{\theta}} =
\begin{bmatrix}
\frac{\partial f}{\partial \theta_1} \\[5pt]
\frac{\partial f}{\partial \theta_2} \\[3pt]
\vdots \\[5pt]
\frac{\partial f}{\partial \theta_k}
\end{bmatrix}
\end{align}\end{split}\]</div>
<p>本当に勾配ベクトル方向が，勾配が最も急な方向を指しているのか，2次元を例に示したのが次の問題である．</p>
</div>
<div class="section" id="[問題]">
<h3>[問題]<a class="headerlink" href="#[問題]" title="Permalink to this headline">¶</a></h3>
<p><span class="math notranslate nohighlight">\(f:\mathbb{R}^2 \to \mathbb{R}\)</span>の関数<span class="math notranslate nohighlight">\(f(x,y)\)</span>のある点<span class="math notranslate nohighlight">\(P(x,y)\)</span>における最大勾配方向が勾配ベクトルの方向と同方向であることを示せ．</p>
<p><strong>解答)</strong></p>
<p>勾配とは，関数<span class="math notranslate nohighlight">\(f\)</span>の変化度合いであり，勾配が最大ということは，関数の変化度合いが最も大きいということである．点<span class="math notranslate nohighlight">\(P(x,y)\)</span>と，そこから微小量<span class="math notranslate nohighlight">\(\Delta x\)</span>，<span class="math notranslate nohighlight">\(\Delta y\)</span>だけ動かした点<span class="math notranslate nohighlight">\(Q(x+\Delta x,y+\Delta y)\)</span>においてそれぞれ関数値を求めて差をとったものを変化度合い<span class="math notranslate nohighlight">\(\Delta f\)</span>とすると，<span class="math notranslate nohighlight">\(\overrightarrow{PQ}=\overrightarrow{OQ}-\overrightarrow{OP}=(\Delta x,\Delta y)\)</span>に注意して，以下の通り変形できる．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
\Delta f &amp;= f(x+\Delta x,y+\Delta y)-f(x,y) \\
&amp;= f(x+\Delta x,y+\Delta y) -f(x,y+\Delta y)+f(x,y+\Delta y) -f(x,y) \\
&amp;= \frac{f(x+\Delta x,y+\Delta y) -f(x,y+\Delta y)}{\Delta x}\Delta x +\frac{f(x,y+\Delta y) -f(x,y)}{\Delta y}\Delta y \\
&amp;\fallingdotseq \frac{\partial f}{\partial x}\Delta x +\frac{\partial f}{\partial y}\Delta y \\
&amp;= \nabla f \cdot (\Delta x,\Delta y) \\
&amp;= \nabla f \cdot \overrightarrow{PQ}
\end{align*}\end{split}\]</div>
<p>すなわちこれは，関数の変化度合いは勾配ベクトルと点<span class="math notranslate nohighlight">\(P\)</span>から点<span class="math notranslate nohighlight">\(Q\)</span>への方向ベクトル，すなわち微小量を動かした方向のベクトルの内積となっている．ここで，角度の定義より，</p>
<div class="math notranslate nohighlight">
\[\begin{align*}
\Delta f &amp;= ||\nabla f||||\overrightarrow{PQ}||\cos \theta
\end{align*}\]</div>
<p>となる．ここで，<span class="math notranslate nohighlight">\(\theta\)</span>は，<span class="math notranslate nohighlight">\(\nabla f\)</span>と<span class="math notranslate nohighlight">\(\overrightarrow{PQ}\)</span>のなす角である．関数の変化度合い<span class="math notranslate nohighlight">\(\Delta f\)</span>が最大となるのは，<span class="math notranslate nohighlight">\(\cos \theta =1\)</span>，すなわち<span class="math notranslate nohighlight">\(\theta =0\)</span>となる場合である．これはつまり<span class="math notranslate nohighlight">\(\nabla f\)</span>と<span class="math notranslate nohighlight">\(\overrightarrow{PQ}\)</span>が同じ方向を向いているときに関数の変化度合い<span class="math notranslate nohighlight">\(\Delta f\)</span>が最大となるということである．以上より，点<span class="math notranslate nohighlight">\(P\)</span>から関数の変化度合い<span class="math notranslate nohighlight">\(\Delta f\)</span>が最大となるように進むためには(点<span class="math notranslate nohighlight">\(Q\)</span>をとるためには)，勾配ベクトルの方向に進めばよいということである．</p>
<p>これで勾配が最も急な方向が勾配ベクトル方向であることがわかったので，それを用いて最急降下法を以下の通り定義する．</p>
</div>
<div class="section" id="[定義]-最急降下法">
<h3>[定義] 最急降下法<a class="headerlink" href="#[定義]-最急降下法" title="Permalink to this headline">¶</a></h3>
<p>関数<span class="math notranslate nohighlight">\(J(\mathbf{\theta})\)</span>を最小とする<span class="math notranslate nohighlight">\(\mathbf{\theta}\)</span>を次の手順で見つけるアルゴリズムを，<strong>最急降下法(gradient descent algorithm)</strong>という．ここで，<span class="math notranslate nohighlight">\(\alpha (&gt;0)\)</span>を<strong>学習率(learning rate)</strong>といい，勾配が最大の方向にどの程度移動させるかの強さを表す．</p>
<ol class="arabic simple">
<li>トレーニングセット<span class="math notranslate nohighlight">\(\{(\mathbf{x}^{(i)},y^{(i)})\}_{i=1}^m\)</span>，仮説関数<span class="math notranslate nohighlight">\(h_{\mathbf{\theta}}(\mathbf{x})\)</span>，目的関数<span class="math notranslate nohighlight">\(J(\mathbf{\theta})\)</span>を用意．</li>
<li>$:nbsphinx-math:<cite>alpha `:nbsphinx-math:</cite>gets <cite>:math:`初期値，</cite><span class="math">\mathbf{\theta}</span> :nbsphinx-math:<a href="#id18"><span class="problematic" id="id19">`</span></a>gets <a href="#id20"><span class="problematic" id="id21">`</span></a>$初期値</li>
<li>以下を<span class="math notranslate nohighlight">\(\mathbf{\theta}\)</span>が収束するまでまたは有限回繰り返し<ol class="arabic">
<li><span class="math notranslate nohighlight">\(\{(\mathbf{x}^{(i)},y^{(i)})\}_{i=1}^m\)</span>を代入して<span class="math notranslate nohighlight">\(J(\mathbf{\theta})\)</span>を計算</li>
<li><span class="math notranslate nohighlight">\(\nabla_{\mathbf{\theta}}J\)</span>を計算</li>
<li><span class="math notranslate nohighlight">\(\mathbf{\theta} \gets \mathbf{\theta}-\alpha \nabla_{\mathbf{\theta}}J\)</span>　(パラメータ$:nbsphinx-math:<cite>theta</cite>_0,:nbsphinx-math:<cite>theta</cite>_1:nbsphinx-math:<a href="#id22"><span class="problematic" id="id23">`</span></a>ldots <a href="#id24"><span class="problematic" id="id25">`</span></a>$は同タイミングで更新)</li>
</ol>
</li>
<li>得られた<span class="math notranslate nohighlight">\(\mathbf{\theta}\)</span>が<span class="math notranslate nohighlight">\(J(\mathbf{\theta})\)</span>を最小とする<span class="math notranslate nohighlight">\(\mathbf{\theta}\)</span>となる．</li>
</ol>
</div>
<div class="section" id="[問題]">
<h3>[問題]<a class="headerlink" href="#[問題]" title="Permalink to this headline">¶</a></h3>
<p><span class="math notranslate nohighlight">\(x_0^{(i)}=1\)</span>も含め特徴量が<span class="math notranslate nohighlight">\(n+1\)</span>個のトレーニングセット<span class="math notranslate nohighlight">\(\{(\mathbf{x}^{(i)},y^{(i)})\}_{i=1}^m\)</span>の線形回帰において，目的関数<span class="math notranslate nohighlight">\(J(\mathbf{\theta})\)</span>を平均二乗誤差関数としたとき，<span class="math notranslate nohighlight">\(\nabla_{\mathbf{\theta}}J\)</span>を計算せよ．</p>
<p><strong>解答)</strong></p>
<p><span class="math notranslate nohighlight">\(\nabla_{\mathbf{\theta}}J\)</span>の<span class="math notranslate nohighlight">\(j\)</span>番目の要素<span class="math notranslate nohighlight">\(\frac{\partial J}{\partial \theta_j}\)</span>を計算すると以下となる．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
\frac{\partial J}{\partial \theta_j}&amp;= \frac{1}{2m}\sum_{i=1}^m \frac{\partial }{\partial \theta_j}(h_{\mathbf{\theta}}(\mathbf{x}^{(i)})-y^{(i)})^2 \\
&amp;=\frac{1}{2m}\sum_{i=1}^m 2(h_{\mathbf{\theta}}(\mathbf{x}^{(i)})-y^{(i)})\frac{\partial }{\partial \theta_j}h_{\mathbf{\theta}}(\mathbf{x}^{(i)})\\
&amp;= \frac{1}{m}\sum_{i=1}^m (h_{\mathbf{\theta}}(\mathbf{x}^{(i)})-y^{(i)})x_j^{(i)}
\end{align*}\end{split}\]</div>
<p><span class="math notranslate nohighlight">\(j=0\)</span>のときは<span class="math notranslate nohighlight">\(\frac{\partial }{\partial \theta_0}h_{\mathbf{\theta}}(\mathbf{x}^{(i)})=1\)</span>であることに注意してまとめると，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
\nabla_{\mathbf{\theta}}J =\frac{1}{m}
\begin{bmatrix}
\sum_{i=1}^m (h_{\mathbf{\theta}}(\mathbf{x}^{(i)})-y^{(i)}) \\[3pt]
\sum_{i=1}^m (h_{\mathbf{\theta}}(\mathbf{x}^{(i)})-y^{(i)})x_1^{(i)} \\[3pt]
\sum_{i=1}^m (h_{\mathbf{\theta}}(\mathbf{x}^{(i)})-y^{(i)})x_2^{(i)} \\[3pt]
\vdots \\[3pt]
\sum_{i=1}^m (h_{\mathbf{\theta}}(\mathbf{x}^{(i)})-y^{(i)})x_j^{(i)} \\[3pt]
\vdots \\[3pt]
\sum_{i=1}^m (h_{\mathbf{\theta}}(\mathbf{x}^{(i)})-y^{(i)})x_n^{(i)} \\[3pt]
\end{bmatrix}\tag{3}
\end{align}\end{split}\]</div>
<p>となる（<span class="math notranslate nohighlight">\(\nabla_{\mathbf{\theta}}J\)</span>は<span class="math notranslate nohighlight">\(n+1\)</span>次元ベクトルである）．</p>
</div>
</div>
<div class="section" id="デザイン行列">
<h2>デザイン行列<a class="headerlink" href="#デザイン行列" title="Permalink to this headline">¶</a></h2>
<p>最急降下法アルゴリズムは， 式(3)を用いて<span class="math notranslate nohighlight">\(\nabla_{\mathbf{\theta}}J\)</span>の各要素に対して逐次計算を行っていけば単純に実装できるが，各要素に対して和の計算を行い，反復していくことは少々ややこしい．行列計算を容易に行えるプログラミング言語で実装する場合には，できるだけ逐次計算をしないように，行列計算やベクトル計算を用いて工夫して実装することが簡潔かつバグも少ない．ここでは，デザイン行列を定義し，行列計算により<span class="math notranslate nohighlight">\(\nabla_{\mathbf{\theta}}J\)</span>を計算できることを示す．</p>
<div class="section" id="[定義]-デザイン行列">
<h3>[定義] デザイン行列<a class="headerlink" href="#[定義]-デザイン行列" title="Permalink to this headline">¶</a></h3>
<p><span class="math notranslate nohighlight">\(x_0^{(i)}=1\)</span>も含め特徴量が<span class="math notranslate nohighlight">\(n+1\)</span>個のトレーニングセット<span class="math notranslate nohighlight">\(\{(\mathbf{x}^{(i)},y^{(i)})\}_{i=1}^m\subset ((1 \times \mathbb{R}^n) \times \mathbb{R})^m\)</span>において，式(4)で定義する行列<span class="math notranslate nohighlight">\(X \in \mathbb{R}^{m\times (n+1)}\)</span>を<strong>デザイン行列(design matrix)</strong>という．デザイン行列は，特徴量<span class="math notranslate nohighlight">\(\mathbf{x}^{(i)}\)</span>を転置してサンプル数の分縦に並べたもので表される．ここで，特徴量として<span class="math notranslate nohighlight">\(x_0=1\)</span>が加わっていることに注意する．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
X =
\begin{bmatrix}
\mbox{------} &amp; {\mathbf{x}^{(1)}}^T &amp; \mbox{------} \\
\mbox{------} &amp; {\mathbf{x}^{(2)}}^T &amp; \mbox{------} \\
 &amp; \vdots &amp; \\
\mbox{------} &amp; {\mathbf{x}^{(m)}}^T &amp; \mbox{------}
\end{bmatrix}
=
\begin{bmatrix}
1 &amp; x_1^{(1)} &amp; x_2^{(1)} &amp; \cdots &amp; x_n^{(1)} \\
1 &amp; x_1^{(2)} &amp; x_2^{(2)} &amp; \cdots &amp; x_n^{(2)} \\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
1 &amp; x_1^{(m)} &amp; x_2^{(m)} &amp; \cdots &amp; x_n^{(m)}
\end{bmatrix} \tag{4}
\end{align}\end{split}\]</div>
</div>
<div class="section" id="[問題]">
<h3>[問題]<a class="headerlink" href="#[問題]" title="Permalink to this headline">¶</a></h3>
<p>次のトレーニングセットにおいて，デザイン行列<span class="math notranslate nohighlight">\(X\)</span>を答えよ．</p>
<table border="1" class="docutils">
<colgroup>
<col width="11%" />
<col width="18%" />
<col width="18%" />
<col width="18%" />
<col width="18%" />
<col width="16%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><span class="math notranslate nohighlight">\(i\)</span></th>
<th class="head"><span class="math notranslate nohighlight">\(x_1^{(i)}\)</span></th>
<th class="head"><span class="math notranslate nohighlight">\(x_2^{(i)}\)</span></th>
<th class="head"><span class="math notranslate nohighlight">\(x_3^{(i)}\)</span></th>
<th class="head"><span class="math notranslate nohighlight">\(x_4^{(i)}\)</span></th>
<th class="head"><span class="math notranslate nohighlight">\(y^{(i)}\)</span></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>1</td>
<td>2104</td>
<td>5</td>
<td>1</td>
<td>45</td>
<td>460</td>
</tr>
<tr class="row-odd"><td>2</td>
<td>1416</td>
<td>3</td>
<td>2</td>
<td>40</td>
<td>232</td>
</tr>
<tr class="row-even"><td>3</td>
<td>1534</td>
<td>3</td>
<td>2</td>
<td>30</td>
<td>315</td>
</tr>
<tr class="row-odd"><td>4</td>
<td>852</td>
<td>2</td>
<td>1</td>
<td>36</td>
<td>178</td>
</tr>
</tbody>
</table>
<p><strong>解答)</strong></p>
<p>サンプル数が4つで，特徴量が<span class="math notranslate nohighlight">\(x_0=1\)</span>を含めると5つなので，<span class="math notranslate nohighlight">\(X\)</span>は以下のような<span class="math notranslate nohighlight">\(4\times 5\)</span>次元の行列となる．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
X=
\begin{bmatrix}
1 &amp; 2104 &amp; 5 &amp; 1 &amp; 45 \\
1 &amp; 1416 &amp; 3 &amp; 2 &amp; 40 \\
1 &amp; 1534 &amp; 3 &amp; 2 &amp; 30 \\
1 &amp; 852  &amp; 2 &amp; 1 &amp; 36
\end{bmatrix}
\end{align*}\end{split}\]</div>
<p>デザイン行列を使うと，予測値である線形回帰の仮説関数のベクトルを簡潔に表すことができ，1発の線形代数計算で予測値を計算できる．</p>
</div>
<div class="section" id="[問題]">
<h3>[問題]<a class="headerlink" href="#[問題]" title="Permalink to this headline">¶</a></h3>
<p><span class="math notranslate nohighlight">\(x_0^{(i)}=1\)</span>も含め特徴量が<span class="math notranslate nohighlight">\(n+1\)</span>個のトレーニングセット<span class="math notranslate nohighlight">\(\{(\mathbf{x}^{(i)},y^{(i)})\}_{i=1}^m\)</span>における線形回帰問題を考える．このとき，<span class="math notranslate nohighlight">\((h_{\mathbf{\theta}}(\mathbf{x}^{(1)}),h_{\mathbf{\theta}}(\mathbf{x}^{(2)}),\ldots,h_{\mathbf{\theta}}(\mathbf{x}^{(m)}))^T\)</span>を<span class="math notranslate nohighlight">\(X\)</span>，<span class="math notranslate nohighlight">\(\mathbf{\theta}\)</span>を用いて表せ．</p>
<p><strong>解答)</strong></p>
<p>線形代数の式(7)より，以下のように変形すれば<span class="math notranslate nohighlight">\(X\)</span>と<span class="math notranslate nohighlight">\(\mathbf{\theta}\)</span>を用いて表すことができる．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
\begin{bmatrix}
h_{\mathbf{\theta}}(\mathbf{x}^{(1)}) \\
h_{\mathbf{\theta}}(\mathbf{x}^{(2)}) \\
\vdots \\
h_{\mathbf{\theta}}(\mathbf{x}^{(m)})
\end{bmatrix}
=
\begin{bmatrix}
\mathbf{\theta}^T\mathbf{x}^{(1)} \\
\mathbf{\theta}^T \mathbf{x}^{(2)}\\
\vdots \\
\mathbf{\theta}^T \mathbf{x}^{(m)}
\end{bmatrix}
=
\begin{bmatrix}
{\mathbf{x}^{(1)}}^T\mathbf{\theta} \\
{\mathbf{x}^{(2)}}^T\mathbf{\theta} \\
\vdots \\
{\mathbf{x}^{(m)}}^T\mathbf{\theta}
\end{bmatrix}
=
\begin{bmatrix}
\mbox{------} &amp; {\mathbf{x}^{(1)}}^T &amp; \mbox{------} \\
\mbox{------} &amp; {\mathbf{x}^{(2)}}^T &amp; \mbox{------} \\
 &amp; \vdots &amp; \\
\mbox{------} &amp; {\mathbf{x}^{(m)}}^T &amp; \mbox{------}
\end{bmatrix}
\begin{bmatrix}
| \\[-2pt]
| \\
\mathbf{\theta} \\
| \\[-2pt]
|
\end{bmatrix}
=X \mathbf{\theta} \tag{5}
\end{align}\end{split}\]</div>
<p>この結果を用いることで，目的関数を平均二乗誤差関数とした線形回帰問題において，目的関数をより簡潔に表すことができる．</p>
</div>
<div class="section" id="[問題]">
<h3>[問題]<a class="headerlink" href="#[問題]" title="Permalink to this headline">¶</a></h3>
<p><span class="math notranslate nohighlight">\(x_0^{(i)}=1\)</span>も含め特徴量が<span class="math notranslate nohighlight">\(n+1\)</span>個のトレーニングセット<span class="math notranslate nohighlight">\(\{(\mathbf{x}^{(i)},y^{(i)})\}_{i=1}^m\)</span>における線形回帰問題において，目的関数<span class="math notranslate nohighlight">\(J(\mathbf{\theta})\)</span>を平均二乗誤差関数とする．このとき，<span class="math notranslate nohighlight">\(J(\mathbf{\theta})\)</span>を<span class="math notranslate nohighlight">\(X\)</span>，<span class="math notranslate nohighlight">\(\mathbf{\theta}\)</span>，<span class="math notranslate nohighlight">\(\mathbf{y}\)</span>を用いて表せ．ここで，<span class="math notranslate nohighlight">\(\mathbf{y}=(y^{(1)},y^{(2)},\ldots,y^{(m)})^T\)</span>とする．</p>
<p><strong>解答)</strong></p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
J(\mathbf{\theta})&amp;= \frac{1}{2m}\sum_{i=1}^m (h_{\mathbf{\theta}}(\mathbf{x}^{(i)})-y^{(i)})^2 \nonumber \\
&amp;=\frac{1}{2m}
\begin{bmatrix}
h_{\mathbf{\theta}}(\mathbf{x}^{(1)})-y^{(1)} &amp; h_{\mathbf{\theta}}(\mathbf{x}^{(2)})-y^{(2)} &amp; \cdots &amp; h_{\mathbf{\theta}}(\mathbf{x}^{(m)})-y^{(m)}
\end{bmatrix}
\begin{bmatrix}
h_{\mathbf{\theta}}(\mathbf{x}^{(1)})-y^{(1)} \\
h_{\mathbf{\theta}}(\mathbf{x}^{(2)})-y^{(2)} \\
\vdots \\
h_{\mathbf{\theta}}(\mathbf{x}^{(m)})-y^{(m)}
\end{bmatrix}\nonumber
\end{align}\end{split}\]</div>
<p>となるが，ここで，式(5)を用いると</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
\begin{bmatrix}
h_{\mathbf{\theta}}(\mathbf{x}^{(1)})-y^{(1)} \\
h_{\mathbf{\theta}}(\mathbf{x}^{(2)})-y^{(2)} \\
\vdots \\
h_{\mathbf{\theta}}(\mathbf{x}^{(m)})-y^{(m)}
\end{bmatrix}
=
\begin{bmatrix}
h_{\mathbf{\theta}}(\mathbf{x}^{(1)}) \\
h_{\mathbf{\theta}}(\mathbf{x}^{(2)}) \\
\vdots \\
h_{\mathbf{\theta}}(\mathbf{x}^{(m)})
\end{bmatrix}
-
\begin{bmatrix}
y^{(1)} \\
y^{(2)} \\
\vdots \\
y^{(m)}
\end{bmatrix}
=X\mathbf{\theta}-\mathbf{y} \nonumber
\end{align}\end{split}\]</div>
<p>となるため，</p>
<div class="math notranslate nohighlight">
\[\begin{align}
J(\mathbf{\theta})&amp;= \frac{1}{2m}(X\mathbf{\theta}-\mathbf{y})^T(X\mathbf{\theta}-\mathbf{y}) \label{lr_cost}
\end{align}\]</div>
<p>これで目的関数を簡潔に書けたので，最後にそれを微分して<span class="math notranslate nohighlight">\(\nabla_{\mathbf{\theta}}J\)</span>を求める．ここで，線形形式，二次形式の勾配ベクトルを使用するので事前に述べておく．</p>
</div>
<div class="section" id="[定理]">
<h3>[定理]<a class="headerlink" href="#[定理]" title="Permalink to this headline">¶</a></h3>
<p><span class="math notranslate nohighlight">\(n\)</span>次元列ベクトル<span class="math notranslate nohighlight">\(\mathbf{x}，\mathbf{a}\)</span>，<span class="math notranslate nohighlight">\(n\times n\)</span>行列<span class="math notranslate nohighlight">\(A\)</span>に対して，次式が成り立つ．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
\nabla_{\mathbf{x}}(\mathbf{a}^T \mathbf{x})&amp;=\nabla_{\mathbf{x}}(\mathbf{x}^T \mathbf{a})=\mathbf{a}\\
\nabla_{\mathbf{x}}(\mathbf{x}^T A\mathbf{x})&amp;=(A+A^T)\mathbf{x}
\end{align}\end{split}\]</div>
<p><strong>証明)</strong></p>
<p>線形形式の勾配ベクトルの証明は略．二次形式の勾配ベクトルは線形代数の式(12)から計算すると楽である．式(12)において，<span class="math notranslate nohighlight">\(x_i\)</span>における偏微分を計算すると以下となる．変形の最後は，<span class="math notranslate nohighlight">\(A=\{a_{ij}\}\)</span>の転置行列を<span class="math notranslate nohighlight">\(A^T=\{a'_{ij}\}\)</span>としたとき，<span class="math notranslate nohighlight">\(a_{ki}=a'_{ik}\)</span>であることを使用している．</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
\frac{\partial }{\partial x_i}(\mathbf{x}^T A\mathbf{x})&amp;=\frac{\partial }{\partial x_i}\left(a_{ii}x_i^2+\sum_{\substack{j=1\\j\neq i}}^n a_{ij}x_ix_j+\sum_{\substack{k=1\\k\neq i}}^n a_{ki}x_kx_i+\sum_{\substack{j,k\\j\neq i\\k\neq i}}a_{kj}x_kx_j\right)    \\
&amp;=2a_{ii}x_i+\sum_{\substack{j=1\\j\neq i}}^n a_{ij}x_j+\sum_{\substack{k=1\\k\neq i}}^n a_{ki}x_k\\
&amp;=\sum_{j=1}^na_{ij}x_j+\sum_{k=1}^na_{ki}x_k\\
&amp;=\sum_{j=1}^na_{ij}x_j+\sum_{k=1}^na'_{ik}x_k
\end{align*}\end{split}\]</div>
<p>第1項について，<span class="math notranslate nohighlight">\(x_1〜x_n\)</span>についての結果を列ベクトルとして並べると，線形代数の式(8)の形が現れ，その結果は<span class="math notranslate nohighlight">\(A\mathbf{x}\)</span>となる．第2項についても同様であり，その結果は<span class="math notranslate nohighlight">\(A^T\mathbf{x}\)</span>となる．以上より，<span class="math notranslate nohighlight">\(\nabla_{\mathbf{x}}(\mathbf{x}^T A\mathbf{x})=A\mathbf{x}+A^T\mathbf{x}=(A+A^T)\mathbf{x}\)</span>である．</p>
</div>
<div class="section" id="[問題]">
<h3>[問題]<a class="headerlink" href="#[問題]" title="Permalink to this headline">¶</a></h3>
<p><span class="math notranslate nohighlight">\(x_0^{(i)}=1\)</span>も含め特徴量が<span class="math notranslate nohighlight">\(n+1\)</span>個のトレーニングセット<span class="math notranslate nohighlight">\(\{(\mathbf{x}^{(i)},y^{(i)})\}_{i=1}^m\)</span>における線形回帰問題において，目的関数<span class="math notranslate nohighlight">\(J(\mathbf{\theta})\)</span>を平均二乗誤差関数とする．このとき，<span class="math notranslate nohighlight">\(\nabla_{\mathbf{\theta}}J\)</span>を<span class="math notranslate nohighlight">\(m\)</span>，<span class="math notranslate nohighlight">\(X\)</span>，<span class="math notranslate nohighlight">\(\mathbf{\theta}\)</span>，<span class="math notranslate nohighlight">\(\mathbf{y}\)</span>で表せ．</p>
<p><strong>解答)</strong></p>
<p><span class="math notranslate nohighlight">\(X^TX\)</span>は対称行列であることに注意すると，</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
\nabla_{\mathbf{\theta}}J&amp;=\nabla_{\mathbf{\theta}}\left(\frac{1}{2m}(X\mathbf{\theta}-\mathbf{y})^T(X\mathbf{\theta}-\mathbf{y})\right) \nonumber\\
&amp;=\nabla_{\mathbf{\theta}}\left(\frac{1}{2m}\left((X\mathbf{\theta})^T(X\mathbf{\theta})-(X\mathbf{\theta})^T\mathbf{y}-\mathbf{y}^T(X\mathbf{\theta})+\mathbf{y}^T\mathbf{y}\right)\right)\nonumber\\
&amp;=\nabla_{\mathbf{\theta}}\left(\frac{1}{2m}\left((X\mathbf{\theta})^T(X\mathbf{\theta})-2(X\mathbf{\theta})^T\mathbf{y}+\mathbf{y}^T\mathbf{y}\right)\right)\nonumber\\
&amp;=\nabla_{\mathbf{\theta}}\left(\frac{1}{2m}\left( \mathbf{\theta}^TX^TX\mathbf{\theta}-2\mathbf{\theta}^TX^T\mathbf{y}+\mathbf{y}^T\mathbf{y} \right)\right) \nonumber\\
&amp;=\frac{1}{2m}\left(\nabla_{\mathbf{\theta}}(\mathbf{\theta}^TX^TX\mathbf{\theta})-2\nabla_{\mathbf{\theta}}(\mathbf{\theta}^TX^T\mathbf{y})+\nabla_{\mathbf{\theta}}(\mathbf{y}^T\mathbf{y})\right)\nonumber\\
&amp;=\frac{1}{2m}\left(2X^TX\mathbf{\theta}-2X^T\mathbf{y}\right)\nonumber \\
&amp;=\frac{1}{m}\left(X^TX\mathbf{\theta}-X^T\mathbf{y}\right) \label{LRglad}
\end{align}\end{split}\]</div>
</div>
</div>
<div class="section" id="Pandas,-Numpy,-Matplotlibによるスクラッチ実装">
<h2>Pandas, Numpy, Matplotlibによるスクラッチ実装<a class="headerlink" href="#Pandas,-Numpy,-Matplotlibによるスクラッチ実装" title="Permalink to this headline">¶</a></h2>
<p>以上で線形回帰で必要なパーツは揃ったので，これらのパーツを実際にPythonにて実装していきながら，線形回帰とはどういうものかを掴んでいく.</p>
</div>
<div class="section" id="kaggle-APIによるデータのダウンロード">
<h2>kaggle APIによるデータのダウンロード<a class="headerlink" href="#kaggle-APIによるデータのダウンロード" title="Permalink to this headline">¶</a></h2>
<p>まずはデータを準備する．データはkaggleのコンペティションのデータセットを使用する．そのために，まずはkaggleのアカウントを作成し，kaggle APIのパッケージをインストールする．アカウントの作成やkaggle APIのインストールの詳細は省略するが，インターネットで検索すれば情報は容易に取得可能である(なお，kaggle APIの公式ドキュメントは<a class="reference external" href="https://www.kaggle.com/docs/api">URL</a>を参照)．以降，kaggle APIが使用可能な状態であることを前提とする．</p>
<p>さて，早速kaggle APIから使用するデータをダウンロードする．ダウンロードするデータは，kaggleの初心者向けコンペである<a class="reference external" href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques/">House Prices: Advanced Regression Techniques</a>とする．</p>
<p>これから，kaggle APIを用いて，これを今使用しているnotebookが格納されているフォルダの中に新しく作成したサブフォルダ<code class="docutils literal notranslate"><span class="pre">house_data</span></code>の中にダウンロードすることを行う．</p>
<p>Jupyterは，ターミナルを開かずとも，その場でbashコマンドを実行することができる．</p>
<div class="section" id="[Jupyter]-エクスクラメーションによるbashコマンドの実行">
<h3>[Jupyter] エクスクラメーションによるbashコマンドの実行<a class="headerlink" href="#[Jupyter]-エクスクラメーションによるbashコマンドの実行" title="Permalink to this headline">¶</a></h3>
<p>エクスクラメーション<code class="docutils literal notranslate"><span class="pre">!</span></code>を文頭につけることでbashコマンドを実行することができる．なお，bashのカレントディレクトリはbashコマンドを打ち込んでいるnotebookが格納されているフォルダである．</p>
<p>以下のコマンドで，カレントディレクトリとなるフォルダの中に，サブフォルダ<code class="docutils literal notranslate"><span class="pre">house_data</span></code>を作成する．</p>
</div>
<div class="section" id="[bash]-フォルダの作成">
<h3>[bash] フォルダの作成<a class="headerlink" href="#[bash]-フォルダの作成" title="Permalink to this headline">¶</a></h3>
<p>フォルダを作成するには，<code class="docutils literal notranslate"><span class="pre">mkdir</span> <span class="pre">フォルダ名</span></code>を実行する．なお，以下の<code class="docutils literal notranslate"><span class="pre">./</span></code>とは，「カレントディレクトリの」という意味だと思えば問題ない．</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>mkdir ./house_data
</pre></div>
</div>
</div>
<p>作成したフォルダにHouse Prices: Advanced Regression Techniquesのデータをダウンロードする．まずは，kaggle APIで，開催中のコンペティションのリストを表示する(もちろん実行時期によって出力は異なる)．</p>
</div>
<div class="section" id="[kaggle-API]-開催中のコンペティションのリストを表示">
<h3>[kaggle API] 開催中のコンペティションのリストを表示<a class="headerlink" href="#[kaggle-API]-開催中のコンペティションのリストを表示" title="Permalink to this headline">¶</a></h3>
<p>開催中のコンペティションのリストを表示するには，<code class="docutils literal notranslate"><span class="pre">kaggle</span> <span class="pre">competitions</span> <span class="pre">list</span></code>を実行する．</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>kaggle competitions list
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
ref                                            deadline             category            reward  teamCount  userHasEntered
---------------------------------------------  -------------------  ---------------  ---------  ---------  --------------
digit-recognizer                               2030-01-01 00:00:00  Getting Started  Knowledge       2573            True
titanic                                        2030-01-01 00:00:00  Getting Started  Knowledge      10333            True
house-prices-advanced-regression-techniques    2030-01-01 00:00:00  Getting Started  Knowledge       4067            True
imagenet-object-localization-challenge         2029-12-31 07:00:00  Research         Knowledge         36           False
competitive-data-science-predict-future-sales  2019-12-31 23:59:00  Playground           Kudos       2571           False
two-sigma-financial-news                       2019-07-15 23:59:00  Featured          $100,000       2927            True
aerial-cactus-identification                   2019-07-08 23:59:00  Playground       Knowledge        146           False
LANL-Earthquake-Prediction                     2019-06-03 23:59:00  Research           $50,000       1922            True
tmdb-box-office-prediction                     2019-05-30 23:59:00  Playground       Knowledge        477           False
dont-overfit-ii                                2019-05-07 23:59:00  Playground            Swag       1215           False
data-science-for-good-careervillage            2019-04-23 23:59:00  Analytics          $15,000          0           False
gendered-pronoun-resolution                    2019-04-22 23:59:00  Research           $25,000        479            True
career-con-2019                                2019-04-11 23:59:00  Recruitment           Swag        728           False
santander-customer-transaction-prediction      2019-04-10 23:59:00  Featured           $65,000       6888           False
mens-machine-learning-competition-2019         2019-04-09 23:59:00  Featured           $25,000        871           False
histopathologic-cancer-detection               2019-03-30 23:59:00  Playground       Knowledge       1031           False
petfinder-adoption-prediction                  2019-03-28 23:59:00  Featured           $25,000       1901            True
womens-machine-learning-competition-2019       2019-03-22 15:00:00  Featured           $25,000        461           False
vsb-power-line-fault-detection                 2019-03-21 23:59:00  Featured           $25,000       1485            True
microsoft-malware-prediction                   2019-03-13 23:59:00  Research           $25,000       2426            True
</pre></div></div>
</div>
<p>ダウンロードしたいのは<code class="docutils literal notranslate"><span class="pre">house-prices-advanced-regression-techniques</span></code>である．これをカレントディレクトリ直下に作成した<code class="docutils literal notranslate"><span class="pre">house_data</span></code>フォルダにダウンロードするには，以下を実行する．</p>
</div>
<div class="section" id="[kaggle-API]-指定したコンペのデータを任意のフォルダにダウンロード">
<h3>[kaggle API] 指定したコンペのデータを任意のフォルダにダウンロード<a class="headerlink" href="#[kaggle-API]-指定したコンペのデータを任意のフォルダにダウンロード" title="Permalink to this headline">¶</a></h3>
<p>指定したコンペのデータを任意のフォルダにダウンロードするには，<code class="docutils literal notranslate"><span class="pre">kaggle</span> <span class="pre">competitions</span> <span class="pre">download</span> <span class="pre">-c</span> <span class="pre">コンペ名</span> <span class="pre">-p</span> <span class="pre">フォルダ</span></code>を実行する．</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>kaggle competitions download -c house-prices-advanced-regression-techniques -p ./house_data
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Downloading sample_submission.csv to ./house_data
  0%|                                               | 0.00/31.2k [00:00&lt;?, ?B/s]
100%|██████████████████████████████████████| 31.2k/31.2k [00:00&lt;00:00, 16.8MB/s]
Downloading test.csv to ./house_data
  0%|                                                | 0.00/441k [00:00&lt;?, ?B/s]
100%|████████████████████████████████████████| 441k/441k [00:00&lt;00:00, 6.01MB/s]
Downloading train.csv to ./house_data
  0%|                                                | 0.00/450k [00:00&lt;?, ?B/s]
100%|████████████████████████████████████████| 450k/450k [00:00&lt;00:00, 13.8MB/s]
Downloading data_description.txt to ./house_data
  0%|                                               | 0.00/13.1k [00:00&lt;?, ?B/s]
100%|██████████████████████████████████████| 13.1k/13.1k [00:00&lt;00:00, 16.9MB/s]
</pre></div></div>
</div>
<p>確かにダウンロードできているかを確認してみる．</p>
</div>
<div class="section" id="[bash]-任意のフォルダに格納されているファイルを確認する">
<h3>[bash] 任意のフォルダに格納されているファイルを確認する<a class="headerlink" href="#[bash]-任意のフォルダに格納されているファイルを確認する" title="Permalink to this headline">¶</a></h3>
<p>任意のフォルダに格納されているファイルを確認するには，<code class="docutils literal notranslate"><span class="pre">ls</span> <span class="pre">フォルダ</span></code>を実行する．</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="o">!</span>ls ./house_data
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
data_description.txt  test.csv
sample_submission.csv train.csv
</pre></div></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="reference.html" class="btn btn-neutral float-right" title="参考文献" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="20190316.html" class="btn btn-neutral" title="機械学習の概念" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Keishi Okudera

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    

  

  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>